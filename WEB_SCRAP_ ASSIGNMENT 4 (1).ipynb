{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6838d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impoting libraries \n",
    "import selenium \n",
    "import pandas as pd \n",
    "import time \n",
    "from bs4 import BeautifulSoup \n",
    "# importing selenium webdriver \n",
    "from selenium import webdriver\n",
    "# importing required Exceptions which needs to handled \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "# importing request \n",
    "import requests \n",
    "from selenium.webdriver.common.by import By \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c714a79f",
   "metadata": {},
   "source": [
    "# 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "\n",
    "A) Rank \n",
    "B) Name \n",
    "C) Artist \n",
    "D) Upload date \n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "322c9202",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a4af13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the Wikipedia page on automated chrome browser\n",
    "\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee819e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping the required detaails \n",
    "\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "tags_rank=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]//td[1]')\n",
    "for i in tags_rank:\n",
    "    try:\n",
    "        Rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Rank.append('-')\n",
    "        \n",
    "tags_name=driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]//td[2]')\n",
    "for i in tags_name:\n",
    "    try:\n",
    "        Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append('-')\n",
    "        \n",
    "tags_artist=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]//td[3]')\n",
    "for i in tags_artist:\n",
    "    try:\n",
    "        Artist.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist.append('-')\n",
    "        \n",
    "tags_publish=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]//td[5]')\n",
    "for i in tags_publish:\n",
    "    try:\n",
    "        Upload_date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Upload_date.append('-')\n",
    "        \n",
    "        \n",
    "tags_views=driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]//td[4]')\n",
    "for i in tags_views:\n",
    "    try:\n",
    "        Views.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Views.append('-')\n",
    "       \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4254672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name Of Video</th>\n",
       "      <th>Uploder Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>View In Billions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[39]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[42]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Sorry\"[43]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[44]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Thinking Out Loud\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[47]</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"[48]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Faded\"[49]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"[52]</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"[53]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                    Name Of Video  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    7.                          \"Wheels on the Bus\"[26]   \n",
       "7    8.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                             \"Counting Stars\"[39]   \n",
       "16  17.                                       \"Roar\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.           \"Waka Waka (This Time for Africa)\"[42]   \n",
       "19  20.                                      \"Sorry\"[43]   \n",
       "20  21.                             \"Lakdi Ki Kathi\"[44]   \n",
       "21  22.                          \"Thinking Out Loud\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.          \"Humpty the train on a fruits ride\"[47]   \n",
       "24  25.                                    \"Perfect\"[48]   \n",
       "25  26.                                      \"Faded\"[49]   \n",
       "26  27.                                 \"Let Her Go\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                    \"Lean On\"[52]   \n",
       "29  30.                                   \"Bailando\"[53]   \n",
       "\n",
       "                                       Uploder Artist        Upload Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                      Justin Bieber   October 22, 2015   \n",
       "20                                       Jingle Toons      June 14, 2018   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22                                         Katy Perry  February 20, 2014   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                        Alan Walker   December 3, 2015   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                           Maroon 5       May 31, 2018   \n",
       "28                               Major Lazer Official     March 22, 2015   \n",
       "29                                   Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   View In Billions  \n",
       "0             13.36  \n",
       "1              8.26  \n",
       "2              6.80  \n",
       "3              6.41  \n",
       "4              6.08  \n",
       "5              6.03  \n",
       "6              5.56  \n",
       "7              5.48  \n",
       "8              5.03  \n",
       "9              4.97  \n",
       "10             4.90  \n",
       "11             4.56  \n",
       "12             4.44  \n",
       "13             4.06  \n",
       "14             3.93  \n",
       "15             3.87  \n",
       "16             3.87  \n",
       "17             3.78  \n",
       "18             3.73  \n",
       "19             3.71  \n",
       "20             3.69  \n",
       "21             3.66  \n",
       "22             3.59  \n",
       "23             3.55  \n",
       "24             3.54  \n",
       "25             3.51  \n",
       "26             3.51  \n",
       "27             3.48  \n",
       "28             3.46  \n",
       "29             3.45  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'Name Of Video':Name,'Uploder Artist':Artist,'Upload Date':Upload_date,'View In Billions':Views })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80459eb2",
   "metadata": {},
   "source": [
    "# 2.  Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/.\n",
    "# You need to find following details: \n",
    "# A) Match title (I.e. 1 ODI) \n",
    "# B) Series \n",
    "# C) Place \n",
    "# D) Date \n",
    "# E) Time \n",
    "# Note: - From bcci.tv home page you have reach to the international fixture page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d4458657",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43b01cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the bcci page on automated chrome browser\n",
    "\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3716bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search international button on web page \n",
    "search=driver.find_element(By.XPATH,\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a\")\n",
    "search.click()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "492d580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search All team button on web page \n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[1]\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "debdbe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search team india  on web page \n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div/div/div/div[2]/div[2]/div/div[4]/div/div[2]/div[7]\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd694379",
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "\n",
    "tags_match=driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]')\n",
    "for i in tags_match:\n",
    "    try:\n",
    "        Match_title.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Match_title.append('-')\n",
    "        \n",
    "tags_vs=driver.find_elements(By.XPATH,' //div[@class=\"match-card-middle__inner d-flex justify-content-between\"]')\n",
    "for i in tags_vs:\n",
    "    try:\n",
    "        Series.append(i.text.replace('\\n',' '))\n",
    "    except NoSuchElementException:\n",
    "        Series.append('-')\n",
    "        \n",
    "tags_place=driver.find_elements(By.XPATH,'//div[@class=\"match-card-bottom\"]')\n",
    "for i in tags_place:\n",
    "    try:\n",
    "        Place.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append('-')\n",
    "        \n",
    "tags_date=driver.find_elements(By.XPATH,'//div[@class=\"match-dates ng-binding\"]')\n",
    "for i in tags_date:\n",
    "    try:\n",
    "        Date.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('-')\n",
    "        \n",
    "        \n",
    "tags_time=driver.find_elements(By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')\n",
    "for i in tags_time:\n",
    "    try:\n",
    "        Time.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Time.append('-')\n",
    "       \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "769e0111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 (8, (8, (8, (8, 8))))\n"
     ]
    }
   ],
   "source": [
    "print(len(Match_title),(len(Series),(len(Place),(len(Date),(len(Date),(len(Time)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "160a6745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>place</th>\n",
       "      <th>Series</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5th ODI -</td>\n",
       "      <td>5th ODI - R Premadasa International Stadium, C...</td>\n",
       "      <td>India vs Bangladesh</td>\n",
       "      <td>15 SEP 2023</td>\n",
       "      <td>10:30 AM WAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>1st ODI - Punjab Cricket Association IS Bindra...</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>9:00 AM WAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>2nd ODI - Holkar Cricket Stadium, Indore\\nMatc...</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>9:00 AM WAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>3rd ODI - Saurashtra Cricket Association Stadi...</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>9:00 AM WAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>1st ODI - Barsapara Cricket Stadium, Guwahati\\...</td>\n",
       "      <td>India vs England</td>\n",
       "      <td>30 SEP 2023</td>\n",
       "      <td>9:30 AM WAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>1st T20I - Pingfeng Cricket Field, Hangzhou\\nM...</td>\n",
       "      <td>India vs TBD</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>2:00 AM WAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>2nd ODI - Greenfield International Stadium, Th...</td>\n",
       "      <td>India vs Netherlands</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>9:30 AM WAST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>1st ODI - MA Chidambaram Stadium, Chennai\\nMat...</td>\n",
       "      <td>India vs Australia</td>\n",
       "      <td>8 OCT 2023</td>\n",
       "      <td>9:30 AM WAST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                                              place  \\\n",
       "0   5th ODI -  5th ODI - R Premadasa International Stadium, C...   \n",
       "1   1st ODI -  1st ODI - Punjab Cricket Association IS Bindra...   \n",
       "2   2nd ODI -  2nd ODI - Holkar Cricket Stadium, Indore\\nMatc...   \n",
       "3   3rd ODI -  3rd ODI - Saurashtra Cricket Association Stadi...   \n",
       "4   1st ODI -  1st ODI - Barsapara Cricket Stadium, Guwahati\\...   \n",
       "5  1st T20I -  1st T20I - Pingfeng Cricket Field, Hangzhou\\nM...   \n",
       "6   2nd ODI -  2nd ODI - Greenfield International Stadium, Th...   \n",
       "7   1st ODI -  1st ODI - MA Chidambaram Stadium, Chennai\\nMat...   \n",
       "\n",
       "                 Series         Date           Time  \n",
       "0   India vs Bangladesh  15 SEP 2023  10:30 AM WAST  \n",
       "1    India vs Australia  22 SEP 2023   9:00 AM WAST  \n",
       "2    India vs Australia  24 SEP 2023   9:00 AM WAST  \n",
       "3    India vs Australia  27 SEP 2023   9:00 AM WAST  \n",
       "4      India vs England  30 SEP 2023   9:30 AM WAST  \n",
       "5          India vs TBD   3 OCT 2023   2:00 AM WAST  \n",
       "6  India vs Netherlands   3 OCT 2023   9:30 AM WAST  \n",
       "7    India vs Australia   8 OCT 2023   9:30 AM WAST  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df=pd.DataFrame({'Match Title':Match_title,'place':Place,'Series':Series,\"Date\":Date,'Time':Time})\n",
    "Df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ae9c5",
   "metadata": {},
   "source": [
    "# 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "# Url = http://statisticstimes.com/\n",
    "# You have to find following details: \n",
    "# A)Rank \n",
    "# B) State \n",
    "# C) GSDP(18-19)- at current prices \n",
    "# D) GSDP(19-20)- at current prices \n",
    "# E) Share(18-19) \n",
    "# F) GDP($ billion)\n",
    "# Note - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cce1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6822351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the statisticstimes  page on automated chrome browser\n",
    "\n",
    "driver.get(' http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a21c9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search Economic button on web page \n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[1]/div[2]/div[2]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ee482fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching for Gdp india states.\n",
    "\n",
    "gdp_india_states_search=driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\")\n",
    "gdp_india_states_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e95c193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eco_Rank=[]\n",
    "States=[]\n",
    "GSDP_18_19_curr_prices =[]\n",
    "GSDP_19_20_curr_prices=[]\n",
    "Shares_18_19=[]\n",
    "GDP_Billion_Dollars=[]\n",
    "\n",
    "\n",
    "tags_rank=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]//td[1]') # scraping for rank\n",
    "for i in tags_rank:\n",
    "    try:\n",
    "        Eco_Rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Eco_Rank.append('-')\n",
    "        \n",
    "tags_states=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]//td[2]')\n",
    "for i in tags_states:\n",
    "    try:\n",
    "        States.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        States.append('-')\n",
    "        \n",
    "tags_gsdp_18_19=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]//td[4]')\n",
    "for i in tags_gsdp_18_19:\n",
    "    try:\n",
    "        GSDP_18_19_curr_prices.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP_18_19_curr_prices.append('-')\n",
    "        \n",
    "tags_gsdp_19_20=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]//td[3]')\n",
    "for i in tags_gsdp_19_20:\n",
    "    try:\n",
    "        GSDP_19_20_curr_prices.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        GSDP_19_20_curr_prices.append('-')\n",
    "        \n",
    "        \n",
    "tags_shares=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]//td[5]')\n",
    "for i in tags_shares:\n",
    "    try:\n",
    "        Shares_18_19.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Shares_18_19.append('-')\n",
    "\n",
    "tags_gdp_b=driver.find_elements(By.XPATH,'//div[@id=\"table_id_wrapper\"]//td[6]')\n",
    "for i in tags_gdp_b:\n",
    "    try:\n",
    "        GDP_Billion_Dollars.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        GDP_Billion_Dollars.append('-')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b84bc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>States</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>India</td>\n",
       "      <td>18,886,957</td>\n",
       "      <td>20,351,013</td>\n",
       "      <td></td>\n",
       "      <td>2,869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                     States GSDP(18-19)- at current prices   \\\n",
       "0     1                Maharashtra                       2,632,792   \n",
       "1     2                 Tamil Nadu                       1,630,208   \n",
       "2     3              Uttar Pradesh                       1,584,764   \n",
       "3     4                    Gujarat                       1,502,899   \n",
       "4     5                  Karnataka                       1,493,127   \n",
       "5     6                West Bengal                       1,089,898   \n",
       "6     7                  Rajasthan                         942,586   \n",
       "7     8             Andhra Pradesh                         862,957   \n",
       "8     9                  Telangana                         861,031   \n",
       "9    10             Madhya Pradesh                         809,592   \n",
       "10   11                     Kerala                         781,653   \n",
       "11   12                      Delhi                         774,870   \n",
       "12   13                    Haryana                         734,163   \n",
       "13   14                      Bihar                         530,363   \n",
       "14   15                     Punjab                         526,376   \n",
       "15   16                     Odisha                         487,805   \n",
       "16   17                      Assam                         315,881   \n",
       "17   18               Chhattisgarh                         304,063   \n",
       "18   19                  Jharkhand                         297,204   \n",
       "19   20                Uttarakhand                         245,895   \n",
       "20   21            Jammu & Kashmir                         155,956   \n",
       "21   22           Himachal Pradesh                         153,845   \n",
       "22   23                        Goa                          73,170   \n",
       "23   24                    Tripura                          49,845   \n",
       "24   25                 Chandigarh                          42,114   \n",
       "25   26                 Puducherry                          34,433   \n",
       "26   27                  Meghalaya                          33,481   \n",
       "27   28                     Sikkim                          28,723   \n",
       "28   29                    Manipur                          27,870   \n",
       "29   30                   Nagaland                          27,283   \n",
       "30   31          Arunachal Pradesh                          24,603   \n",
       "31   32                    Mizoram                          22,287   \n",
       "32   33  Andaman & Nicobar Islands                               -   \n",
       "33                           India                      18,886,957   \n",
       "\n",
       "   GSDP(19-20)- at current prices Share(18-19) GDP($ billion)  \n",
       "0                               -       13.94%        399.921  \n",
       "1                       1,845,853        8.63%        247.629  \n",
       "2                       1,687,818        8.39%        240.726  \n",
       "3                               -        7.96%        228.290  \n",
       "4                       1,631,977        7.91%        226.806  \n",
       "5                       1,253,832        5.77%        165.556  \n",
       "6                       1,020,989        4.99%        143.179  \n",
       "7                         972,782        4.57%        131.083  \n",
       "8                         969,604        4.56%        130.791  \n",
       "9                         906,672        4.29%        122.977  \n",
       "10                              -        4.14%        118.733  \n",
       "11                        856,112        4.10%        117.703  \n",
       "12                        831,610        3.89%        111.519  \n",
       "13                        611,804        2.81%         80.562  \n",
       "14                        574,760        2.79%         79.957  \n",
       "15                        521,275        2.58%         74.098  \n",
       "16                              -        1.67%         47.982  \n",
       "17                        329,180        1.61%         46.187  \n",
       "18                        328,598        1.57%         45.145  \n",
       "19                              -        1.30%         37.351  \n",
       "20                              -        0.83%         23.690  \n",
       "21                        165,472        0.81%         23.369  \n",
       "22                         80,449        0.39%         11.115  \n",
       "23                         55,984        0.26%          7.571  \n",
       "24                              -        0.22%          6.397  \n",
       "25                         38,253        0.18%          5.230  \n",
       "26                         36,572        0.18%          5.086  \n",
       "27                         32,496        0.15%          4.363  \n",
       "28                         31,790        0.15%          4.233  \n",
       "29                              -        0.14%          4.144  \n",
       "30                              -        0.13%          3.737  \n",
       "31                         26,503        0.12%          3.385  \n",
       "32                              -            -              -  \n",
       "33                     20,351,013                       2,869  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eco=pd.DataFrame({'Rank':Eco_Rank, 'States':States,'GSDP(18-19)- at current prices ':GSDP_18_19_curr_prices,'GSDP(19-20)- at current prices':GSDP_19_20_curr_prices,'Share(18-19)':Shares_18_19,'GDP($ billion)':GDP_Billion_Dollars})\n",
    "df_eco"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af76639b",
   "metadata": {},
   "source": [
    "# 4. Scrape the details of trending repositories on Github.com. \n",
    "# Url = https://github.com/\n",
    "# You have to find the following details: \n",
    "# A) Repository title \n",
    "# B) Repository description \n",
    "# C) Contributors count \n",
    "# D) Language used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7568d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef9ebaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the github  page on automated chrome browser\n",
    "\n",
    "driver.get(' http://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d1124a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search Open Source button on web page \n",
    "search_trending=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button\")\n",
    "search_trending.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efdd842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search Trending button on web page \n",
    "search_trending=driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a\")\n",
    "search_trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b831a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for the scrapped requirements\n",
    "\n",
    "Repository_title=[]\n",
    "Repository_descript=[]\n",
    "Contributors_counts =[]\n",
    "Language=[]\n",
    "\n",
    "\n",
    "\n",
    "tags_title=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]//a') # Scrapig for Repository Title\n",
    "for i in tags_title:\n",
    "    try:\n",
    "        Repository_title.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append('-')\n",
    "        \n",
    "tags_description=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]//p') # Scraping Repository Description\n",
    "for i in tags_description:\n",
    "    try:\n",
    "        Repository_descript.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_descript.append('-')\n",
    "        \n",
    "tags_counts=driver.find_elements(By.XPATH,'//a[@class=\"Link Link--muted d-inline-block mr-3\"][1]') # scarping Contributors counts\n",
    "for i in tags_counts:\n",
    "    try:\n",
    "        Contributors_counts.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_counts.append('-')\n",
    "        \n",
    "tags_languages=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]') # scaping Language \n",
    "for i in tags_languages:\n",
    "    try:\n",
    "        Language.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0b8b4e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 24\n"
     ]
    }
   ],
   "source": [
    "print(len(Repository_descript),len(Repository_title),len(Contributors_counts),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dd2a4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yoheinakajima / instagraph',\n",
       " 'tldraw / tldraw',\n",
       " 'godotengine / godot',\n",
       " 'lllyasviel / Fooocus',\n",
       " 'FL33TW00D / whisper-turbo',\n",
       " 'keras-team / keras',\n",
       " 'd2l-ai / d2l-zh',\n",
       " 'testerSunshine / 12306',\n",
       " 'godotengine / godot-demo-projects',\n",
       " 'nicolas-hbt / pygraft',\n",
       " 'facebookresearch / nougat',\n",
       " 'FlaxEngine / FlaxEngine',\n",
       " 'ahmetbersoz / chatgpt-prompts-for-academic-writing',\n",
       " 'chaitin / SafeLine',\n",
       " 'massalabs / massa',\n",
       " 'dimdenGD / OldTweetDeck',\n",
       " 'makepad / makepad',\n",
       " 'angular / angular',\n",
       " 'mouredev / Hello-Python',\n",
       " 'AykutSarac / jsoncrack.com',\n",
       " 'facebook / react-native',\n",
       " 'godotengine / godot-docs',\n",
       " 'elementor / elementor',\n",
       " 'vllm-project / vllm',\n",
       " 'jedisct1 / libsodium']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repository_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85efed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Converts text input or URL into knowledge graph and displays',\n",
       " 'a very good whiteboard',\n",
       " 'Godot Engine – Multi-platform 2D and 3D game engine',\n",
       " 'Focus on prompting and generating',\n",
       " 'Whisper on the web - turbocharged by your GPU 🏎️',\n",
       " 'Deep Learning for humans',\n",
       " '《动手学深度学习》：面向中文读者、能运行、可讨论。中英文版被70多个国家的500多所大学用于教学。',\n",
       " '12306智能刷票，订票',\n",
       " 'Demonstration and Template Projects',\n",
       " 'Configurable Generation of Schemas and Knowledge Graphs at Your Fingertips',\n",
       " 'Implementation of Nougat Neural Optical Understanding for Academic Documents',\n",
       " 'Flax Engine – multi-platform 3D game engine',\n",
       " 'This list of writing prompts covers a range of topics and tasks, including brainstorming research ideas, improving language and style, conducting literature reviews, and developing research plans.',\n",
       " '一款足够简单、足够好用、足够强的免费 WAF。基于业界领先的语义引擎检测技术，作为反向代理接入，保护你的网站不受黑客攻击。',\n",
       " 'The Decentralized and Scaled Blockchain',\n",
       " 'Returns old TweetDeck, for free!',\n",
       " 'Makepad is a creative software development platform for Rust that compiles to wasm/webGL, osx/metal, windows/dx11 linux/opengl',\n",
       " 'The modern web developer’s platform',\n",
       " 'Curso para aprender el lenguaje de programación Python desde cero y para principiantes. Más de 30 clases, 25 horas en vídeo, código y grupo de chat. Desde sus fundamentos hasta la creación de un API Backend con base de datos y más...',\n",
       " '✨ Innovative and open-source visualization application that transforms various data formats, such as JSON, YAML, XML, CSV and more, into interactive graphs.',\n",
       " 'A framework for building native applications using React',\n",
       " 'Godot Engine official documentation',\n",
       " 'The most advanced frontend drag & drop page builder. Create high-end, pixel perfect websites at record speeds. Any theme, any page, any design.',\n",
       " 'A high-throughput and memory-efficient inference and serving engine for LLMs',\n",
       " 'A modern, portable, easy to use crypto library.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Repository_descript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67eee069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['651',\n",
       " '18,376',\n",
       " '67,733',\n",
       " '11,807',\n",
       " '577',\n",
       " '59,183',\n",
       " '47,968',\n",
       " '31,358',\n",
       " '3,635',\n",
       " '301',\n",
       " '4,252',\n",
       " '4,186',\n",
       " '536',\n",
       " '4,051',\n",
       " '4,138',\n",
       " '992',\n",
       " '3,893',\n",
       " '90,191',\n",
       " '15,678',\n",
       " '25,158',\n",
       " '111,906',\n",
       " '2,565',\n",
       " '5,341',\n",
       " '6,741',\n",
       " '11,333']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contributors_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "405dddb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python',\n",
       " 'TypeScript',\n",
       " 'C++',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'GDScript',\n",
       " 'Python',\n",
       " 'Python',\n",
       " 'C++',\n",
       " 'C++',\n",
       " 'Rust',\n",
       " 'JavaScript',\n",
       " 'Rust',\n",
       " 'TypeScript',\n",
       " 'Python',\n",
       " 'TypeScript',\n",
       " 'Java',\n",
       " 'reStructuredText',\n",
       " 'JavaScript',\n",
       " 'Python',\n",
       " 'C']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571da2c9",
   "metadata": {},
   "source": [
    "# 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "# You have to find the following details: \n",
    "# A) Song name \n",
    "# B) Artist name \n",
    "# C) Last week rank \n",
    "# D) Peak rank \n",
    "# E) Weeks on board \n",
    "# Note: - From the home page you have to click on the charts option then hot 100-page link through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06943399",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29db9868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the bill baord  page on automated chrome browser\n",
    "\n",
    "driver.get(' http://billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ada727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search home button on web page \n",
    "open_home_button=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div/div[4]/div/div[1]/div[1]/button\")\n",
    "open_home_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46b034fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To open chart button on web page \n",
    "open_chart_button=driver.find_element(By.XPATH,\"/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[1]/div/div[2]\")\n",
    "open_chart_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "645e6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping top 100 songs\n",
    "for _ in range(500): # scroll the page 20 times \n",
    "        driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "        \n",
    "        \n",
    "song_name=[]        \n",
    "tags_title=driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//h3 ')\n",
    "for i in tags_title[0:100]:\n",
    "    try:\n",
    "        song_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        song_name.append('-')\n",
    "        \n",
    "Artist_name=[]\n",
    "tags_artist= driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]//li[1]//span')\n",
    "for i in tags_artist[0:100]:\n",
    "    try:\n",
    "        Artist_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Artist_name.append('-')\n",
    "        \n",
    "last_wk_rank=[]\n",
    "tags_lst_rk= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//li[4]')\n",
    "for i in tags_lst_rk[0:100]:\n",
    "    try:\n",
    "        last_wk_rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        last_wk_rank.append('-')\n",
    "        \n",
    "peak_rank=[]\n",
    "tags_peak= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//li[5]')\n",
    "for i in tags_peak[0:100]:\n",
    "    try:\n",
    "        peak_rank.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        peak_rank.append('-')\n",
    "        \n",
    "wk_on_board=[]\n",
    "tags_board= driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]//li[6]')\n",
    "for i in tags_board[0:100]:\n",
    "    try:\n",
    "        wk_on_board.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        wk_on_board.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eae3c6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(song_name),len(Artist_name),len(last_wk_rank),len(peak_rank),len(wk_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63c8e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Week on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paint The Town Red</td>\n",
       "      <td>Doja Cat</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>Zach Bryan Featuring Kacey Musgraves</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Stand By Me</td>\n",
       "      <td>Lil Durk Featuring Morgan Wallen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Call Your Friends</td>\n",
       "      <td>Rod Wave</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Your Heart Or Mine</td>\n",
       "      <td>Jon Pardi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Primera Cita</td>\n",
       "      <td>Carin Leon</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>S91</td>\n",
       "      <td>Karol G</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Song Name                           Artist Name  \\\n",
       "0      Paint The Town Red                              Doja Cat   \n",
       "1   I Remember Everything  Zach Bryan Featuring Kacey Musgraves   \n",
       "2                Fast Car                            Luke Combs   \n",
       "3            Cruel Summer                          Taylor Swift   \n",
       "4              Last Night                         Morgan Wallen   \n",
       "..                    ...                                   ...   \n",
       "95            Stand By Me      Lil Durk Featuring Morgan Wallen   \n",
       "96      Call Your Friends                              Rod Wave   \n",
       "97     Your Heart Or Mine                             Jon Pardi   \n",
       "98           Primera Cita                            Carin Leon   \n",
       "99                    S91                               Karol G   \n",
       "\n",
       "   last Week Rank Peak Rank Week on Board  \n",
       "0               3         1             5  \n",
       "1                                       2  \n",
       "2               1         1            24  \n",
       "3                                      18  \n",
       "4               2         2            32  \n",
       "..            ...       ...           ...  \n",
       "95                                     15  \n",
       "96             31        31             3  \n",
       "97                                     17  \n",
       "98             55        26             2  \n",
       "99                                      6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bb = pd.DataFrame({'Song Name':song_name,'Artist Name':Artist_name,'last Week Rank':last_wk_rank,'Peak Rank':peak_rank,'Week on Board':wk_on_board})\n",
    "df_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f554c29",
   "metadata": {},
   "source": [
    "# 6. Scrape the details of Highest selling novels. compare \n",
    "# A) Book name \n",
    "# B) Author name \n",
    "# C) Volumes sold \n",
    "# D) Publisher \n",
    "# E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5a454e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973f8763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the theguardian  page on automated chrome browser\n",
    "\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b903e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for the scrapped requirements\n",
    "\n",
    "Book_Name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "\n",
    "\n",
    "tags_name=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[2]') # Scrapig for Book Name \n",
    "for i in tags_name:\n",
    "    try:\n",
    "        Book_Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Book_Name.append('-')\n",
    "        \n",
    "tags_author=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[3]') # Scraping for Author Name \n",
    "for i in tags_author:\n",
    "    try:\n",
    "        Author_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Author_name.append('-')\n",
    "        \n",
    "tags_volumes=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[4]') # scarping Volumes\n",
    "for i in tags_volumes:\n",
    "    try:\n",
    "        Volumes_sold.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Volumes_sold.append('-')\n",
    "        \n",
    "tags_publisher=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[5]') # scaping Publisher\n",
    "for i in tags_publisher:\n",
    "    try:\n",
    "        Publisher.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Publisher.append('-')\n",
    "        \n",
    "tags_genre=driver.find_elements(By.XPATH,'//table[@class=\"in-article sortable\"]//tr//td[6]') # scaping Genre\n",
    "for i in tags_genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc5c0862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b = pd.DataFrame({' Book Name': Book_Name, 'Author Name':Author_name,'Volumes Sold':Volumes_sold,'Publisher':Publisher,'Genre':Genre})\n",
    "df_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd835e7c",
   "metadata": {},
   "source": [
    "# 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "# Url = https://www.imdb.com/list/ls095964455/ You have to find the following details: \n",
    "# A) Name \n",
    "# B) Year span \n",
    "# C) Genre \n",
    "# D) Run time \n",
    "# E) Ratings \n",
    "#F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e30f4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62e06911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the imdb  page on automated chrome browser\n",
    "\n",
    "driver.get(' https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8fe722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping top 100 songs\n",
    "for _ in range(500): # scroll the page 20 times \n",
    "        driver.execute_script(\"window.scrollBy(0,100)\")\n",
    "\n",
    "\n",
    "\n",
    "Movie_Name=[]\n",
    "tags_name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//a') # Scrapig for Movie Name \n",
    "for i in tags_name:\n",
    "    try:\n",
    "        Movie_Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Movie_Name.append('-')\n",
    "        \n",
    "Year_span=[]        \n",
    "tags_year=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]//span[2]') # Scraping for Year Span\n",
    "for i in tags_year:\n",
    "    try:\n",
    "        Year_span.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Year_span.append('-')\n",
    "        \n",
    "Genre=[]        \n",
    "tags_genre=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]//span[5]') # scarping Genre\n",
    "for i in tags_genre:\n",
    "    try:\n",
    "        Genre.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append('-')\n",
    "        \n",
    "        \n",
    "Run_time=[]        \n",
    "tags_time=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]//span[3]') # scaping Run _time \n",
    "for i in tags_time:\n",
    "    try:\n",
    "        Run_time.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Run_time.append('-')\n",
    "        \n",
    "Ratings=[]        \n",
    "tags_ratings=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-star small\"]') # scaping Ratings\n",
    "for i in tags_ratings:\n",
    "    try:\n",
    "        Ratings.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Ratings.append('-')\n",
    "        \n",
    "Votes=[]        \n",
    "tags_vote=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]') # scaping Votes \n",
    "for i in tags_vote:\n",
    "    try:\n",
    "        Votes.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Votes.append('-')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15aaa309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,203,982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,275,583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,045,791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>307,337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>211,024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>265,942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Movie Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2025)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,203,982  \n",
       "1    51 min     8.7  1,275,583  \n",
       "2    44 min     8.1  1,045,791  \n",
       "3    60 min     7.5    307,337  \n",
       "4    43 min     7.6    266,439  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     52,725  \n",
       "96   50 min     7.8     64,777  \n",
       "97   42 min     8.1    211,024  \n",
       "98   45 min       7     43,897  \n",
       "99  572 min     8.6    265,942  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m= pd.DataFrame({'Movie Name':Movie_Name,'Year Span':Year_span,'Genre':Genre,'Run time':Run_time,'Ratings':Ratings,'Votes':Votes})\n",
    "df_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec6be17",
   "metadata": {},
   "source": [
    "# 8. Details of Datasets from UCI machine learning repositories. \n",
    "# Url = https://archive.ics.uci.edu/\n",
    "# You have to find the following details: \n",
    "# A) Dataset name \n",
    "# B) Data type \n",
    "# C) Task \n",
    "# D) Attribute type \n",
    "# E) No of instances \n",
    "# F) No of attribute G) Year \n",
    "# Note: - from the home page you have to go to the Show All Dataset page through code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91884ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d13c2039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the imdb  page on automated chrome browser\n",
    "\n",
    "driver.get(' https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3aa0f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To search home button on web page \n",
    "open_show_more_datasets=driver.find_element(By.XPATH,'//div[@class=\"flex flex-wrap justify-center gap-5\"]//a[1]')\n",
    "open_show_more_datasets.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e6cbe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for the scrapped requirements\n",
    "\n",
    "Datasets_Name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attributeG_year=[]\n",
    "\n",
    "\n",
    "tags_name=driver.find_elements(By.XPATH,'//a[@class=\"link-hover link text-xl font-semibold\"]') # Scrapig for Book Name\n",
    "for i in tags_name:\n",
    "    try:\n",
    "        Datasets_Name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Datasets_Name.append('-')\n",
    "        \n",
    "tags_dt_ty=driver.find_elements(By.XPATH,'//table[@class=\"col-span-full my-2 table sm:col-start-2\"][1]//td[2]') # Scraping for Author Name\n",
    "for i in tags_dt_ty:\n",
    "    try:\n",
    "        Data_type.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "        \n",
    "        \n",
    "tags_task=driver.find_elements(By.XPATH,'//div[@class=\"relative col-span-8 sm:col-span-7\"]//p') # scarping task\n",
    "for i in tags_task:\n",
    "    try:\n",
    "        Task.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "        \n",
    "\n",
    "tags_attribute=driver.find_elements(By.XPATH,'//table[@class=\"col-span-full my-2 table sm:col-start-2\"][1]//td[1]') # scaping No of Attribute\n",
    "for i in tags_attribute:\n",
    "    try:\n",
    "        Attribute_type.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "        \n",
    "\n",
    "tags_instances=driver.find_elements(By.XPATH,'//div[@class=\"col-span-3 flex items-center gap-2\"][3]//span') # scaping No of instance\n",
    "for i in tags_instances:\n",
    "    try:\n",
    "       \n",
    "        No_of_instances.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "\n",
    "tags_year=driver.find_elements(By.XPATH,'//table[@class=\"col-span-full my-2 table sm:col-start-2\"][1]//td[3]') # scaping No of attribute year \n",
    "for i in tags_year:\n",
    "    try:\n",
    "        No_of_attributeG_year.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributeG_year.append('-')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e016421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
